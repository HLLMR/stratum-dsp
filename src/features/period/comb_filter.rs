//! Comb filterbank BPM estimation
//!
//! Tests hypothesis tempos and scores by match quality.
//!
//! # Algorithm
//!
//! This module implements the comb filterbank approach described in
//! Gkiokas et al. (2012). The process:
//!
//! 1. Generate candidate BPM values (e.g., 80-180 BPM, step=1.0)
//! 2. For each candidate, compute expected beat intervals
//! 3. Score by counting onsets aligned with expected beats (±10% tolerance)
//! 4. Normalize scores by total onset count
//! 5. Return candidates ranked by score
//!
//! # Reference
//!
//! Gkiokas, A., Katsouros, V., & Carayannis, G. (2012).
//! Dimensionality Reduction for BPM Estimation.
//! *IEEE Transactions on Audio, Speech, and Language Processing*.
//!
//! # Example
//!
//! ```no_run
//! use stratum_dsp::features::period::comb_filter::estimate_bpm_from_comb_filter;
//!
//! let onsets = vec![0, 11025, 22050, 33075]; // 120 BPM at 44.1kHz
//! let candidates = estimate_bpm_from_comb_filter(
//!     &onsets,
//!     44100,
//!     512,
//!     60.0,
//!     180.0,
//!     1.0,
//! )?;
//! # Ok::<(), stratum_dsp::AnalysisError>(())
//! ```

use super::BpmCandidate;

const EPSILON: f32 = 1e-10;
const DEFAULT_TOLERANCE: f32 = 0.1; // 10% of beat interval (base)
const MIN_TOLERANCE: f32 = 0.05; // 5% minimum
const MAX_TOLERANCE: f32 = 0.15; // 15% maximum
const REFERENCE_BPM: f32 = 120.0; // Reference BPM for adaptive tolerance

/// Estimate BPM from comb filterbank
///
/// This function implements the comb filterbank approach described in Gkiokas et al. (2012).
/// Unlike autocorrelation, which finds periodicity directly, this method tests hypothesis
/// tempos and scores them by how well they align with the observed onsets. This approach
/// is more robust to octave errors and works well when autocorrelation fails.
///
/// # Reference
///
/// Gkiokas, A., Katsouros, V., & Carayannis, G. (2012).
/// Dimensionality Reduction for BPM Estimation.
/// *IEEE Transactions on Audio, Speech, and Language Processing*, 20(3), 865-876.
///
/// # Arguments
///
/// * `onsets` - Onset times in samples
/// * `sample_rate` - Sample rate in Hz
/// * `hop_size` - Hop size used for onset detection (not used directly, but kept for API consistency)
/// * `min_bpm` - Minimum BPM to consider (default: 60.0)
/// * `max_bpm` - Maximum BPM to consider (default: 180.0)
/// * `bpm_resolution` - BPM resolution (default: 1.0, e.g., 0.5 for half-BPM precision)
///   For faster computation, use `coarse_to_fine_search()` which uses 2.0 resolution first
///
/// # Returns
///
/// Vector of BPM candidates ranked by confidence (highest first)
///
/// # Errors
///
/// Returns `AnalysisError` if:
/// - Onset list is empty
/// - Invalid parameters (sample_rate=0, invalid BPM range)
/// - Numerical errors during computation
///
/// # Algorithm Details
///
/// For each candidate BPM:
/// 1. Compute expected beat interval: `period_samples = (60 * sample_rate) / BPM`
/// 2. Generate expected beat times: `[0, period, 2*period, 3*period, ...]`
/// 3. Score by counting onsets within tolerance: `±10% * period`
///    - Tolerance window: ±10% of beat interval (as recommended by Gkiokas et al. 2012)
/// 4. Normalize: `score = aligned_onsets / total_beat_count`
///    - Normalization by beat count (not onset count) gives higher scores to BPMs
///      that align well with the beat grid
///
/// # Performance
///
/// Typical performance: 10-30ms for 30s track (101 candidates, 80-180 BPM, 1.0 resolution)
/// For faster computation, use `coarse_to_fine_search()` which reduces candidate count.
pub fn estimate_bpm_from_comb_filter(
    onsets: &[usize],
    sample_rate: u32,
    _hop_size: usize,
    min_bpm: f32,
    max_bpm: f32,
    bpm_resolution: f32,
) -> Result<Vec<BpmCandidate>, crate::error::AnalysisError> {
    log::debug!(
        "Estimating BPM from comb filter: {} onsets, {} Hz, range=[{:.1}, {:.1}] BPM, resolution={:.2}",
        onsets.len(),
        sample_rate,
        min_bpm,
        max_bpm,
        bpm_resolution
    );

    // Validate inputs
    if onsets.is_empty() {
        return Err(crate::error::AnalysisError::InvalidInput(
            "Empty onset list".to_string(),
        ));
    }

    if sample_rate == 0 {
        return Err(crate::error::AnalysisError::InvalidInput(
            "Invalid sample rate: 0".to_string(),
        ));
    }

    if min_bpm <= 0.0 || max_bpm <= 0.0 || min_bpm >= max_bpm {
        return Err(crate::error::AnalysisError::InvalidInput(format!(
            "Invalid BPM range: [{:.1}, {:.1}]",
            min_bpm, max_bpm
        )));
    }

    if bpm_resolution <= 0.0 {
        return Err(crate::error::AnalysisError::InvalidInput(format!(
            "Invalid BPM resolution: {:.2}",
            bpm_resolution
        )));
    }

    // Need at least 2 onsets for meaningful scoring
    if onsets.len() < 2 {
        log::warn!("Too few onsets for comb filter: {}", onsets.len());
        return Ok(vec![]);
    }

    // Sort onsets for efficient searching
    let mut sorted_onsets = onsets.to_vec();
    sorted_onsets.sort_unstable();

    // Generate candidate BPMs
    let num_candidates = ((max_bpm - min_bpm) / bpm_resolution).ceil() as usize + 1;
    let mut candidates = Vec::with_capacity(num_candidates);

    // Track maximum score for normalization
    let mut max_score = 0.0f32;

    // Test each candidate BPM
    let mut bpm = min_bpm;
    while bpm <= max_bpm + EPSILON {
        // Adaptive tolerance: higher BPM = smaller tolerance (more precise)
        // Lower BPM = larger tolerance (more forgiving)
        // Formula: tolerance = base_tolerance * (reference_bpm / bpm)
        // Clamped to [MIN_TOLERANCE, MAX_TOLERANCE]
        let adaptive_tolerance = (DEFAULT_TOLERANCE * (REFERENCE_BPM / bpm))
            .max(MIN_TOLERANCE)
            .min(MAX_TOLERANCE);

        let score = score_bpm_candidate(&sorted_onsets, sample_rate, bpm, adaptive_tolerance)?;

        if score > max_score {
            max_score = score;
        }

        candidates.push((bpm, score));
        bpm += bpm_resolution;
    }

    // Normalize scores to [0, 1] confidence range
    let normalized_candidates: Vec<BpmCandidate> = if max_score > EPSILON {
        candidates
            .into_iter()
            .map(|(bpm, score)| BpmCandidate {
                bpm,
                confidence: score / max_score,
            })
            .collect()
    } else {
        // All scores are zero
        candidates
            .into_iter()
            .map(|(bpm, _)| BpmCandidate {
                bpm,
                confidence: 0.0,
            })
            .collect()
    };

    // Sort by confidence (highest first)
    let mut result = normalized_candidates;
    result.sort_by(|a, b| {
        b.confidence
            .partial_cmp(&a.confidence)
            .unwrap_or(std::cmp::Ordering::Equal)
    });

    // Filter out very low confidence candidates (< 0.1)
    result.retain(|c| c.confidence >= 0.1);

    log::debug!(
        "Comb filter found {} BPM candidates (max confidence: {:.3})",
        result.len(),
        result.first().map(|c| c.confidence).unwrap_or(0.0)
    );

    Ok(result)
}

/// Estimate BPM using coarse-to-fine search optimization
///
/// This function implements a two-stage search strategy for faster BPM estimation:
/// 1. Coarse search: Test candidates at 2.0 BPM resolution (faster)
/// 2. Fine search: Test candidates at 0.5 BPM resolution around best candidate (±5 BPM)
///
/// This optimization reduces the number of candidates tested while maintaining accuracy,
/// making it suitable for real-time applications or when processing many tracks.
///
/// # Reference
///
/// Gkiokas, A., Katsouros, V., & Carayannis, G. (2012).
/// Dimensionality Reduction for BPM Estimation.
/// *IEEE Transactions on Audio, Speech, and Language Processing*, 20(3), 865-876.
///
/// The coarse-to-fine approach is a common optimization technique mentioned in the paper
/// and related BPM estimation literature.
///
/// # Arguments
///
/// * `onsets` - Onset times in samples
/// * `sample_rate` - Sample rate in Hz
/// * `hop_size` - Hop size used for onset detection (not used directly, but kept for API consistency)
/// * `min_bpm` - Minimum BPM to consider (default: 60.0)
/// * `max_bpm` - Maximum BPM to consider (default: 180.0)
/// * `refinement_range` - BPM range around best candidate for fine search (default: 5.0)
///
/// # Returns
///
/// Vector of BPM candidates ranked by confidence (highest first)
///
/// # Errors
///
/// Returns `AnalysisError` if estimation fails (same as `estimate_bpm_from_comb_filter`)
///
/// # Performance
///
/// Typical performance: 5-15ms for 30s track (vs 10-30ms for full search)
/// Reduces candidate count from ~101 (1.0 resolution) to ~50 (coarse) + ~20 (fine) = ~70 total
pub fn coarse_to_fine_search(
    onsets: &[usize],
    sample_rate: u32,
    hop_size: usize,
    min_bpm: f32,
    max_bpm: f32,
    refinement_range: f32,
) -> Result<Vec<BpmCandidate>, crate::error::AnalysisError> {
    log::debug!(
        "Coarse-to-fine BPM search: {} onsets, {} Hz, range=[{:.1}, {:.1}] BPM",
        onsets.len(),
        sample_rate,
        min_bpm,
        max_bpm
    );

    // Stage 1: Coarse search at 2.0 BPM resolution
    let coarse_candidates = estimate_bpm_from_comb_filter(
        onsets,
        sample_rate,
        hop_size,
        min_bpm,
        max_bpm,
        2.0, // Coarse resolution
    )?;

    if coarse_candidates.is_empty() {
        return Ok(vec![]);
    }

    // Find best candidate from coarse search
    let best_coarse = &coarse_candidates[0];
    let best_bpm = best_coarse.bpm;

    // Stage 2: Fine search around best candidate
    // Search in range [best_bpm - refinement_range, best_bpm + refinement_range]
    let fine_min = (best_bpm - refinement_range).max(min_bpm);
    let fine_max = (best_bpm + refinement_range).min(max_bpm);

    let fine_candidates = estimate_bpm_from_comb_filter(
        onsets,
        sample_rate,
        hop_size,
        fine_min,
        fine_max,
        0.5, // Fine resolution
    )?;

    // Combine results: prefer fine candidates, but include coarse if fine is empty
    let mut result = if !fine_candidates.is_empty() {
        fine_candidates
    } else {
        // Fallback to coarse if fine search found nothing
        coarse_candidates
    };

    // Sort by confidence (highest first)
    result.sort_by(|a, b| {
        b.confidence
            .partial_cmp(&a.confidence)
            .unwrap_or(std::cmp::Ordering::Equal)
    });

    log::debug!(
        "Coarse-to-fine search found {} BPM candidates (best: {:.2} BPM, confidence: {:.3})",
        result.len(),
        result.first().map(|c| c.bpm).unwrap_or(0.0),
        result.first().map(|c| c.confidence).unwrap_or(0.0)
    );

    Ok(result)
}

/// Score a single BPM candidate by counting aligned onsets
///
/// # Arguments
///
/// * `onsets` - Sorted onset times in samples
/// * `sample_rate` - Sample rate in Hz
/// * `bpm` - Candidate BPM to test
/// * `tolerance` - Tolerance as fraction of beat interval (e.g., 0.1 = 10%)
///   This is typically adaptive based on BPM (higher BPM = smaller tolerance)
///
/// # Returns
///
/// Normalized score (0.0-1.0): fraction of expected beats that have aligned onsets
fn score_bpm_candidate(
    onsets: &[usize],
    sample_rate: u32,
    bpm: f32,
    tolerance: f32,
) -> Result<f32, crate::error::AnalysisError> {
    if onsets.is_empty() {
        return Ok(0.0);
    }

    // Compute expected beat interval in samples
    let period_samples = (60.0 * sample_rate as f32) / bpm;

    if period_samples < 1.0 {
        return Err(crate::error::AnalysisError::NumericalError(format!(
            "Invalid period: {:.2} samples for BPM {:.2}",
            period_samples, bpm
        )));
    }

    let tolerance_samples = period_samples * tolerance;

    // Generate expected beat times up to the last onset
    let last_onset = onsets[onsets.len() - 1] as f32;
    let num_beats = (last_onset / period_samples).ceil() as usize + 1;

    // Count aligned onsets
    let mut aligned_count = 0usize;

    for beat_idx in 0..num_beats {
        let expected_beat = (beat_idx as f32) * period_samples;

        // Find nearest onset to this expected beat
        let nearest_onset = onsets
            .iter()
            .min_by_key(|&&onset| ((onset as f32) - expected_beat).abs() as usize)
            .copied();

        if let Some(onset) = nearest_onset {
            let distance = ((onset as f32) - expected_beat).abs();
            if distance <= tolerance_samples {
                aligned_count += 1;
            }
        }
    }

    // Normalize by total number of expected beats (not total onsets)
    // This gives higher scores to BPMs that align well with the beat grid
    let score = if num_beats > 0 {
        aligned_count as f32 / num_beats as f32
    } else {
        0.0
    };

    Ok(score)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_comb_filter_120bpm() {
        // Create onsets for 120 BPM at 44.1kHz
        let sample_rate = 44100;
        let hop_size = 512;
        let bpm = 120.0;
        let period_samples = (60.0 * sample_rate as f32) / bpm;

        // Generate 4 beats worth of onsets
        let mut onsets = Vec::new();
        for beat in 0..4 {
            let sample = (beat as f32 * period_samples).round() as usize;
            onsets.push(sample);
        }

        let candidates =
            estimate_bpm_from_comb_filter(&onsets, sample_rate, hop_size, 60.0, 180.0, 1.0)
                .unwrap();

        assert!(!candidates.is_empty(), "Should find at least one candidate");

        // Best candidate should be close to 120 BPM
        let best = &candidates[0];
        assert!(
            (best.bpm - 120.0).abs() < 5.0,
            "Best BPM should be close to 120, got {:.2}",
            best.bpm
        );
        assert!(best.confidence > 0.0, "Confidence should be positive");
    }

    #[test]
    fn test_comb_filter_empty_onsets() {
        let result = estimate_bpm_from_comb_filter(&[], 44100, 512, 60.0, 180.0, 1.0);
        assert!(result.is_err());
    }

    #[test]
    fn test_comb_filter_single_onset() {
        let onsets = vec![1000];
        let result = estimate_bpm_from_comb_filter(&onsets, 44100, 512, 60.0, 180.0, 1.0);
        assert!(result.is_ok());
        assert!(result.unwrap().is_empty());
    }

    #[test]
    fn test_comb_filter_invalid_params() {
        let onsets = vec![1000, 2000];

        // Invalid sample rate
        let result = estimate_bpm_from_comb_filter(&onsets, 0, 512, 60.0, 180.0, 1.0);
        assert!(result.is_err());

        // Invalid BPM range
        let result = estimate_bpm_from_comb_filter(&onsets, 44100, 512, 180.0, 60.0, 1.0);
        assert!(result.is_err());

        // Invalid resolution
        let result = estimate_bpm_from_comb_filter(&onsets, 44100, 512, 60.0, 180.0, 0.0);
        assert!(result.is_err());
    }

    #[test]
    fn test_comb_filter_128bpm() {
        let sample_rate = 44100;
        let hop_size = 512;
        let bpm = 128.0;
        let period_samples = (60.0 * sample_rate as f32) / bpm;

        let mut onsets = Vec::new();
        for beat in 0..4 {
            let sample = (beat as f32 * period_samples).round() as usize;
            onsets.push(sample);
        }

        let candidates =
            estimate_bpm_from_comb_filter(&onsets, sample_rate, hop_size, 60.0, 180.0, 1.0)
                .unwrap();

        assert!(!candidates.is_empty());
        let best = &candidates[0];
        assert!(
            (best.bpm - 128.0).abs() < 5.0,
            "Best BPM should be close to 128, got {:.2}",
            best.bpm
        );
    }

    #[test]
    fn test_score_bpm_candidate() {
        let sample_rate = 44100;
        let bpm = 120.0;

        // Perfect alignment: onsets at exact beat intervals
        let period_samples = (60.0 * sample_rate as f32) / bpm;
        let perfect_onsets: Vec<usize> = (0..4)
            .map(|beat| (beat as f32 * period_samples).round() as usize)
            .collect();

        let score = score_bpm_candidate(&perfect_onsets, sample_rate, bpm, 0.1).unwrap();
        assert!(
            score > 0.8,
            "Perfect alignment should score high, got {:.3}",
            score
        );

        // Random onsets should score low
        let random_onsets = vec![1000, 5000, 12000, 25000];
        let score = score_bpm_candidate(&random_onsets, sample_rate, bpm, 0.1).unwrap();
        assert!(
            score < 0.5,
            "Random onsets should score low, got {:.3}",
            score
        );
    }

    #[test]
    fn test_comb_filter_resolution() {
        let sample_rate = 44100;
        let hop_size = 512;
        let bpm = 120.0;
        let period_samples = (60.0 * sample_rate as f32) / bpm;

        let mut onsets = Vec::new();
        for beat in 0..4 {
            let sample = (beat as f32 * period_samples).round() as usize;
            onsets.push(sample);
        }

        // Test with different resolutions
        let candidates_1 =
            estimate_bpm_from_comb_filter(&onsets, sample_rate, hop_size, 60.0, 180.0, 1.0)
                .unwrap();

        let candidates_05 =
            estimate_bpm_from_comb_filter(&onsets, sample_rate, hop_size, 60.0, 180.0, 0.5)
                .unwrap();

        // Higher resolution should find more candidates
        assert!(candidates_05.len() >= candidates_1.len());
    }

    #[test]
    fn test_coarse_to_fine_search() {
        let sample_rate = 44100;
        let hop_size = 512;
        let bpm = 120.0;
        let period_samples = (60.0 * sample_rate as f32) / bpm;

        let mut onsets = Vec::new();
        for beat in 0..4 {
            let sample = (beat as f32 * period_samples).round() as usize;
            onsets.push(sample);
        }

        let candidates = coarse_to_fine_search(
            &onsets,
            sample_rate,
            hop_size,
            60.0,
            180.0,
            5.0, // refinement_range
        )
        .unwrap();

        assert!(!candidates.is_empty(), "Should find at least one candidate");

        // Best candidate should be close to 120 BPM
        let best = &candidates[0];
        assert!(
            (best.bpm - 120.0).abs() < 5.0,
            "Best BPM should be close to 120, got {:.2}",
            best.bpm
        );
        assert!(best.confidence > 0.0, "Confidence should be positive");
    }

    #[test]
    fn test_coarse_to_fine_search_empty() {
        let result = coarse_to_fine_search(&[], 44100, 512, 60.0, 180.0, 5.0);
        assert!(result.is_err());
    }

    #[test]
    fn test_coarse_to_fine_search_performance() {
        // Test that coarse-to-fine is faster than full search
        // (We can't easily measure time in unit tests, but we can verify it works)
        let sample_rate = 44100;
        let hop_size = 512;
        let bpm = 128.0;
        let period_samples = (60.0 * sample_rate as f32) / bpm;

        let mut onsets = Vec::new();
        for beat in 0..8 {
            let sample = (beat as f32 * period_samples).round() as usize;
            onsets.push(sample);
        }

        let candidates =
            coarse_to_fine_search(&onsets, sample_rate, hop_size, 60.0, 180.0, 5.0).unwrap();

        assert!(!candidates.is_empty());
        let best = &candidates[0];
        assert!(
            (best.bpm - 128.0).abs() < 5.0,
            "Best BPM should be close to 128, got {:.2}",
            best.bpm
        );
    }
}
